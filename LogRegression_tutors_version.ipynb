{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogRegression_tutors_version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminbenteke/Logistic_regression/blob/main/LogRegression_tutors_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Implementation"
      ],
      "metadata": {
        "id": "3H4HVu_0ckc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions:\n",
        "1. Save a copy of this notebook in your drive;\n",
        "2. Name it by: `Your_fullname_LogRegression.ipynb`\n",
        "3. Close the original notebook\n",
        "4. Start typing your codes.\n",
        "\n",
        "`Note:` Discuss with your neighbors."
      ],
      "metadata": {
        "id": "Tok5c-XqyBfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Data preparation\n",
        "\n",
        "## Import Dataset Libraries"
      ],
      "metadata": {
        "id": "VhL_jPWQZCoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5tJBDqB444I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 0: Import the dataset Dataset"
      ],
      "metadata": {
        "id": "wwf9SiJ4ZEvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### WRITE YOUR CODE HERE #####\n",
        "path= '/content/diabetes.csv'\n",
        "data= pd.read_csv(path)\n",
        "#### END CODE ####"
      ],
      "metadata": {
        "id": "R42UJPRzUYPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: Print the first five rows of the Dataset"
      ],
      "metadata": {
        "id": "cFQTnXLoXgy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### WRITE YOUR CODE HERE #####\n",
        "data.head()\n",
        "#### END CODE ####"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Fj4Vhz42U5fd",
        "outputId": "9efebb28-63d7-4e46-aeb8-f179aec9e997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a16a94c5-2885-47c6-8e8f-438904fc6e57\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a16a94c5-2885-47c6-8e8f-438904fc6e57')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a16a94c5-2885-47c6-8e8f-438904fc6e57 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a16a94c5-2885-47c6-8e8f-438904fc6e57');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Check the types of your variables/features"
      ],
      "metadata": {
        "id": "6iVatSkruxwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### WRITE YOUR CODE HERE #####\n",
        "data.dtypes\n",
        "#### END CODE ####"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM09phY_U8J_",
        "outputId": "68cecd2e-44ae-4285-a55c-aa32be1b5605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                   int64\n",
              "Glucose                       int64\n",
              "BloodPressure                 int64\n",
              "SkinThickness                 int64\n",
              "Insulin                       int64\n",
              "BMI                         float64\n",
              "DiabetesPedigreeFunction    float64\n",
              "Age                           int64\n",
              "Outcome                       int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Describe your dataset"
      ],
      "metadata": {
        "id": "o7idUq99XlAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### WRITE YOUR CODE HERE #####\n",
        "data.describe()\n",
        "#### END CODE ####"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "qWo3tf5dZadO",
        "outputId": "ea4cd0f2-e83a-4ca9-f18d-c86c0cd283b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5f874c24-aab4-4927-8508-e67fe4c505fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f874c24-aab4-4927-8508-e67fe4c505fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f874c24-aab4-4927-8508-e67fe4c505fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f874c24-aab4-4927-8508-e67fe4c505fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Pregnancies     Glucose  ...         Age     Outcome\n",
              "count   768.000000  768.000000  ...  768.000000  768.000000\n",
              "mean      3.845052  120.894531  ...   33.240885    0.348958\n",
              "std       3.369578   31.972618  ...   11.760232    0.476951\n",
              "min       0.000000    0.000000  ...   21.000000    0.000000\n",
              "25%       1.000000   99.000000  ...   24.000000    0.000000\n",
              "50%       3.000000  117.000000  ...   29.000000    0.000000\n",
              "75%       6.000000  140.250000  ...   41.000000    1.000000\n",
              "max      17.000000  199.000000  ...   81.000000    1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: write a function that scale your features.\n",
        "`Hint:` $x'= \\dfrac{x-\\mu}{\\sigma}$ \n",
        "where $\\mu$ is the mean and $\\sigma$ the standard deviation of $x$."
      ],
      "metadata": {
        "id": "XLhl5xo2XpTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### WRITE YOUR CODE HERE #####\n",
        "def scale(x):\n",
        "  return (x-x.mean(0))/x.std(0)\n",
        "#### END CODE ####"
      ],
      "metadata": {
        "id": "uHqEW65wXvNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Scale your features, except the target. "
      ],
      "metadata": {
        "id": "xHrdxls1Xx-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### WRITE YOUR CODE HERE #####\n",
        "data.iloc[:,:-1]= scale(data)\n",
        "print(data)\n",
        "#### END CODE #### "
      ],
      "metadata": {
        "id": "dF2xJum5YAkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4dd3956-77e5-4821-d849-da9daaaa8945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pregnancies   Glucose  ...       Age  Outcome\n",
            "0       0.639530  0.847771  ...  1.425067        1\n",
            "1      -0.844335 -1.122665  ... -0.190548        0\n",
            "2       1.233077  1.942458  ... -0.105515        1\n",
            "3      -0.844335 -0.997558  ... -1.040871        0\n",
            "4      -1.141108  0.503727  ... -0.020483        1\n",
            "..           ...       ...  ...       ...      ...\n",
            "763     1.826623 -0.622237  ...  2.530487        0\n",
            "764    -0.547562  0.034575  ... -0.530677        0\n",
            "765     0.342757  0.003299  ... -0.275580        0\n",
            "766    -0.844335  0.159683  ...  1.169970        1\n",
            "767    -0.844335 -0.872451  ... -0.870806        0\n",
            "\n",
            "[768 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a function that split your (x,y) to (x_train, y_train) and (x_test, y_test).\n",
        "`Note:` This function must return an arrays."
      ],
      "metadata": {
        "id": "EaLTFVDPeeQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### WRITE YOUR CODE HERE #####\n",
        "def split_data(df, train_percent= 0.8):\n",
        "  np.random.seed(2)\n",
        "  perm = np.random.permutation(df.index)\n",
        "\n",
        "  n= len(df)\n",
        "  train_index = int(train_percent * n)\n",
        "\n",
        "  train = df.iloc[perm[:train_index]]\n",
        "  test = df.iloc[perm[train_index:]]\n",
        "\n",
        "  x_train, x_test, y_train, y_test= train.iloc[:, :-1], test.iloc[:, :-1], train.iloc[:, -1], test.iloc[:, -1]\n",
        "  return x_train.values, x_test.values, y_train.values, y_test.values\n",
        "#### END CODE ####"
      ],
      "metadata": {
        "id": "4qE0hOeia1Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test= split_data(data) \n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "gApO25M7b4_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3eb2fb9-ba43-4fc6-9173-d059732684a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((614, 8), (614,), (154, 8), (154,))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Logistic Regression without Regularization.\n",
        "\n",
        "## Recaps:\n",
        "1. Logistic/sigmoid function of $z$:\n",
        "\\begin{equation}\n",
        "g(z)= \\dfrac{1}{1+ exp(-z)}\n",
        "\\end{equation}\n",
        "where $z= x^t \\theta$ and $x, y \\in \\mathbb{R}^d$.\n",
        "2. Derivative of Logistic/sigmoid function with respective to $z$:\n",
        "\\begin{equation}\n",
        "dg(z)= g(z)(1-g(z))\n",
        "\\end{equation}\n",
        "3. Cross-entropy loss:\n",
        "\\begin{equation}\n",
        "l(\\theta)= -\\sum_{i= 1}^{N} \\left(y_{true} \\times \\log y_{pred} + (1-y_{true}) \\times \\log (1-y_{pred}) \\right)\n",
        "\\end{equation}\n",
        "where $y_{true}= g(z)$, $z= x^t \\theta$ and $y_{true}$ is the ground-truth for a given $x$.\n",
        "\n",
        "4. Derivative of Cross-entropy loss with respective to $\\theta$:\n",
        "\\begin{equation}\n",
        "dl(\\theta)= -\\sum_{i= 1}^{N} x^t\\left(y_{true} -y_{ped} \\right)\n",
        "\\end{equation}\n",
        "5. Apply Batch gradient descent to update $\\theta$.\n",
        "\n",
        "Question: Create a class called LogReg. See the description in the below cells.\n"
      ],
      "metadata": {
        "id": "-iHA8LO0dq05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class logistic_regression:\n",
        "  def __init__(self, num_iters= 100, threshold= 0.5, tolerance= 1e-10, lr= 0.00001):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    self.num_iters= num_iters\n",
        "    self.threshold= threshold\n",
        "    self.tolerance= tolerance\n",
        "    self.lr= lr\n",
        "    self.theta= None\n",
        "    self.cost_history= []\n",
        "    #### END CODE ####\n",
        "\n",
        "  def add_ones(self, x):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    x_new= np.concatenate((np.ones((len(x),1)), x), axis = 1)\n",
        "    return x_new\n",
        "    #### END CODE ####\n",
        "\n",
        "  def sigmoid(self, x, theta):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    z= x@theta\n",
        "    return 1/(1 + np.exp(z))\n",
        "    #### END CODE ####\n",
        "\n",
        "  def cross_entropy(self, x, y_true):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    n = x.shape[0]\n",
        "    y_hat = self.sigmoid(x, self.theta)\n",
        "    temp_theta = self.theta[1:].copy()\n",
        "\n",
        "    Cost = -np.sum(y_true*np.log(y_hat)+(1-y_true)*np.log(1-y_hat))/len(x)\n",
        "        \n",
        "    return Cost\n",
        "    #### END CODE ####\n",
        "\n",
        "  def fit(self, x,y):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    x= self.add_ones(x) # Add ones to x\n",
        "    y= y.reshape(-1, 1) # reshape y. This is optional, do it if needed\n",
        "    self.theta= np.zeros((x.shape[1], 1))# Initialize theta to zeros vector >>> (x.shape[1])\n",
        "    current_iter= 1\n",
        "    norm= 1\n",
        "\n",
        "    while (norm >= self.tolerance and current_iter < self.num_iters):\n",
        "      theta_old = self.theta.copy() # Get old theta\n",
        "\n",
        "      # make predictions\n",
        "      y_pred= self.sigmoid(x, self.theta) # using sigmoid function \n",
        "\n",
        "      # Gradient of cross-entropy\n",
        "      grad= x.T@(y - y_pred)\n",
        "      grad= grad.reshape(-1, 1) # Reshape, if it is needed\n",
        "\n",
        "      # update rules\n",
        "      self.theta= self.theta - self.lr*grad\n",
        "      # Compute the training loss\n",
        "      self.cost_history.append(self.cross_entropy(x, y))\n",
        "\n",
        "      # Convergence criteria:\n",
        "      if current_iter%100 == 0:\n",
        "        print(f'cost for {current_iter} iteration : {self.cross_entropy(x, y)}')\n",
        "      norm = np.linalg.norm(theta_old - self.theta)\n",
        "      current_iter += 1\n",
        "    #### END CODE ####\n",
        "  \n",
        "  def predict(self, x):\n",
        "    proba= self.predict_proba(x) # Get probability of x\n",
        "    result= [1 if i> self.threshold else 0 for i in proba] # Convert proba to 0 or 1. hint: list comprehension\n",
        "    return np.array(result) \n",
        "  \n",
        "    \n",
        "  def predict_proba(self, x):\n",
        "    x= x= self.add_ones(x) # Apply add ones to x\n",
        "    y_pred_prob= self.sigmoid(x, self.theta) # Predict proba with sigmoid\n",
        "    return y_pred_prob\n",
        "  \n",
        "  def plot(self):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Cost')\n",
        "    plt.plot(np.arange(len(self.cost_history)), self.cost_history, 'r', linewidth = \"2\")\n",
        "    plt.show()\n",
        "    #### END CODE ####"
      ],
      "metadata": {
        "id": "fcwOt19ygOVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model by instanciating the class logistic_regression\n",
        "model = logistic_regression(num_iters=10000)"
      ],
      "metadata": {
        "id": "PyAKBcDvgOYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdezNg1egOb9",
        "outputId": "7002144f-6081-4d36-a2b6-40c3dd7ac766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost for 100 iteration : 0.6362373605032056\n",
            "cost for 200 iteration : 0.5988470249186553\n",
            "cost for 300 iteration : 0.5731266601190665\n",
            "cost for 400 iteration : 0.5546596118987498\n",
            "cost for 500 iteration : 0.5409170138988207\n",
            "cost for 600 iteration : 0.5303898928558933\n",
            "cost for 700 iteration : 0.5221361975391885\n",
            "cost for 800 iteration : 0.5155423018805115\n",
            "cost for 900 iteration : 0.5101931110081553\n",
            "cost for 1000 iteration : 0.5057984298137365\n",
            "cost for 1100 iteration : 0.5021495355459176\n",
            "cost for 1200 iteration : 0.49909259434535147\n",
            "cost for 1300 iteration : 0.49651182432058544\n",
            "cost for 1400 iteration : 0.49431849661589616\n",
            "cost for 1500 iteration : 0.4924435467133995\n",
            "cost for 1600 iteration : 0.4908324847043871\n",
            "cost for 1700 iteration : 0.489441809331206\n",
            "cost for 1800 iteration : 0.4882364300560567\n",
            "cost for 1900 iteration : 0.4871877801040583\n",
            "cost for 2000 iteration : 0.48627241286696055\n",
            "cost for 2100 iteration : 0.485470942723045\n",
            "cost for 2200 iteration : 0.4847672353998577\n",
            "cost for 2300 iteration : 0.4841477818920112\n",
            "cost for 2400 iteration : 0.4836012092532888\n",
            "cost for 2500 iteration : 0.4831178947242058\n",
            "cost for 2600 iteration : 0.4826896587540938\n",
            "cost for 2700 iteration : 0.4823095188744711\n",
            "cost for 2800 iteration : 0.4819714909448642\n",
            "cost for 2900 iteration : 0.48167042759244216\n",
            "cost for 3000 iteration : 0.48140188608246187\n",
            "cost for 3100 iteration : 0.4811620196448118\n",
            "cost for 3200 iteration : 0.4809474876196708\n",
            "cost for 3300 iteration : 0.4807553807956448\n",
            "cost for 3400 iteration : 0.48058315908359994\n",
            "cost for 3500 iteration : 0.480428599260872\n",
            "cost for 3600 iteration : 0.48028975097836424\n",
            "cost for 3700 iteration : 0.48016489957997954\n",
            "cost for 3800 iteration : 0.48005253456392233\n",
            "cost for 3900 iteration : 0.4799513227365528\n",
            "cost for 4000 iteration : 0.47986008528510443\n",
            "cost for 4100 iteration : 0.479777778135803\n",
            "cost for 4200 iteration : 0.4797034750764696\n",
            "cost for 4300 iteration : 0.4796363532134561\n",
            "cost for 4400 iteration : 0.47957568040629617\n",
            "cost for 4500 iteration : 0.4795208043833043\n",
            "cost for 4600 iteration : 0.4794711432902505\n",
            "cost for 4700 iteration : 0.47942617746437177\n",
            "cost for 4800 iteration : 0.47938544225902224\n",
            "cost for 4900 iteration : 0.4793485217715861\n",
            "cost for 5000 iteration : 0.47931504334994046\n",
            "cost for 5100 iteration : 0.4792846727716249\n",
            "cost for 5200 iteration : 0.4792571100056271\n",
            "cost for 5300 iteration : 0.4792320854798967\n",
            "cost for 5400 iteration : 0.47920935678879667\n",
            "cost for 5500 iteration : 0.47918870578404477\n",
            "cost for 5600 iteration : 0.4791699360006103\n",
            "cost for 5700 iteration : 0.4791528703757207\n",
            "cost for 5800 iteration : 0.4791373492248335\n",
            "cost for 5900 iteration : 0.4791232284432731\n",
            "cost for 6000 iteration : 0.47911037790637934\n",
            "cost for 6100 iteration : 0.4790986800445573\n",
            "cost for 6200 iteration : 0.4790880285726645\n",
            "cost for 6300 iteration : 0.4790783273557897\n",
            "cost for 6400 iteration : 0.47906948939572974\n",
            "cost for 6500 iteration : 0.4790614359244259\n",
            "cost for 6600 iteration : 0.479054095592303\n",
            "cost for 6700 iteration : 0.47904740374091986\n",
            "cost for 6800 iteration : 0.47904130175061016\n",
            "cost for 6900 iteration : 0.47903573645489733\n",
            "cost for 7000 iteration : 0.47903065961443636\n",
            "cost for 7100 iteration : 0.479026027444071\n",
            "cost for 7200 iteration : 0.4790218001873391\n",
            "cost for 7300 iteration : 0.4790179417333983\n",
            "cost for 7400 iteration : 0.4790144192719181\n",
            "cost for 7500 iteration : 0.47901120298197564\n",
            "cost for 7600 iteration : 0.4790082657514358\n",
            "cost for 7700 iteration : 0.4790055829236825\n",
            "cost for 7800 iteration : 0.4790031320689062\n",
            "cost for 7900 iteration : 0.4790008927774589\n",
            "cost for 8000 iteration : 0.47899884647304913\n",
            "cost for 8100 iteration : 0.47899697624379295\n",
            "cost for 8200 iteration : 0.47899526668933834\n",
            "cost for 8300 iteration : 0.4789937037824757\n",
            "cost for 8400 iteration : 0.47899227474380257\n",
            "cost for 8500 iteration : 0.47899096792816964\n",
            "cost for 8600 iteration : 0.4789897727217549\n",
            "cost for 8700 iteration : 0.47898867944873735\n",
            "cost for 8800 iteration : 0.4789876792866441\n",
            "cost for 8900 iteration : 0.47898676418953695\n",
            "cost for 9000 iteration : 0.47898592681828867\n",
            "cost for 9100 iteration : 0.4789851604772743\n",
            "cost for 9200 iteration : 0.47898445905686776\n",
            "cost for 9300 iteration : 0.4789838169811986\n",
            "cost for 9400 iteration : 0.47898322916066965\n",
            "cost for 9500 iteration : 0.47898269094879325\n",
            "cost for 9600 iteration : 0.4789821981029402\n",
            "cost for 9700 iteration : 0.4789817467486381\n",
            "cost for 9800 iteration : 0.47898133334709037\n",
            "cost for 9900 iteration : 0.4789809546656182\n",
            "CPU times: user 1.15 s, sys: 19.9 ms, total: 1.17 s\n",
            "Wall time: 1.17 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred= model.predict(x_test)"
      ],
      "metadata": {
        "id": "OvI1XF0Wju9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3izqcnB6Tm4R",
        "outputId": "c743d761-c241-4ab3-ffe0-79a5b3904ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Proba\n",
        "print(model.predict_proba(x_test))"
      ],
      "metadata": {
        "id": "8PozH_SWVTI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a45b862-90cb-4ec4-e106-ab987481cbb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0621]\n",
            " [0.1436]\n",
            " [0.1677]\n",
            " [0.0565]\n",
            " [0.6866]\n",
            " [0.5908]\n",
            " [0.2401]\n",
            " [0.2425]\n",
            " [0.0385]\n",
            " [0.1886]\n",
            " [0.0447]\n",
            " [0.3099]\n",
            " [0.6544]\n",
            " [0.0178]\n",
            " [0.6413]\n",
            " [0.0529]\n",
            " [0.3717]\n",
            " [0.494 ]\n",
            " [0.3416]\n",
            " [0.0737]\n",
            " [0.271 ]\n",
            " [0.4752]\n",
            " [0.4347]\n",
            " [0.192 ]\n",
            " [0.2511]\n",
            " [0.804 ]\n",
            " [0.1115]\n",
            " [0.4247]\n",
            " [0.4134]\n",
            " [0.207 ]\n",
            " [0.0308]\n",
            " [0.9211]\n",
            " [0.0705]\n",
            " [0.4055]\n",
            " [0.0706]\n",
            " [0.4636]\n",
            " [0.7279]\n",
            " [0.4458]\n",
            " [0.1158]\n",
            " [0.9547]\n",
            " [0.0936]\n",
            " [0.2659]\n",
            " [0.8375]\n",
            " [0.9143]\n",
            " [0.2087]\n",
            " [0.0789]\n",
            " [0.2372]\n",
            " [0.7176]\n",
            " [0.4112]\n",
            " [0.3573]\n",
            " [0.2549]\n",
            " [0.677 ]\n",
            " [0.7355]\n",
            " [0.0229]\n",
            " [0.4227]\n",
            " [0.1864]\n",
            " [0.304 ]\n",
            " [0.7764]\n",
            " [0.143 ]\n",
            " [0.9133]\n",
            " [0.9494]\n",
            " [0.3878]\n",
            " [0.1288]\n",
            " [0.0699]\n",
            " [0.1692]\n",
            " [0.0835]\n",
            " [0.0611]\n",
            " [0.0546]\n",
            " [0.3898]\n",
            " [0.5423]\n",
            " [0.5947]\n",
            " [0.5072]\n",
            " [0.0057]\n",
            " [0.0165]\n",
            " [0.1788]\n",
            " [0.0876]\n",
            " [0.9268]\n",
            " [0.8461]\n",
            " [0.2378]\n",
            " [0.8072]\n",
            " [0.5071]\n",
            " [0.0742]\n",
            " [0.0381]\n",
            " [0.4086]\n",
            " [0.2687]\n",
            " [0.8279]\n",
            " [0.7836]\n",
            " [0.2676]\n",
            " [0.1783]\n",
            " [0.0875]\n",
            " [0.0528]\n",
            " [0.0772]\n",
            " [0.1533]\n",
            " [0.2506]\n",
            " [0.1097]\n",
            " [0.0481]\n",
            " [0.8506]\n",
            " [0.3916]\n",
            " [0.0769]\n",
            " [0.7196]\n",
            " [0.0705]\n",
            " [0.6671]\n",
            " [0.1556]\n",
            " [0.1056]\n",
            " [0.42  ]\n",
            " [0.8467]\n",
            " [0.7172]\n",
            " [0.7724]\n",
            " [0.619 ]\n",
            " [0.0348]\n",
            " [0.7504]\n",
            " [0.0942]\n",
            " [0.4437]\n",
            " [0.024 ]\n",
            " [0.501 ]\n",
            " [0.2663]\n",
            " [0.5537]\n",
            " [0.3205]\n",
            " [0.2166]\n",
            " [0.099 ]\n",
            " [0.7486]\n",
            " [0.7353]\n",
            " [0.2164]\n",
            " [0.6824]\n",
            " [0.2107]\n",
            " [0.0938]\n",
            " [0.7995]\n",
            " [0.1042]\n",
            " [0.8241]\n",
            " [0.0852]\n",
            " [0.0641]\n",
            " [0.6288]\n",
            " [0.0594]\n",
            " [0.4169]\n",
            " [0.146 ]\n",
            " [0.7145]\n",
            " [0.2228]\n",
            " [0.4345]\n",
            " [0.0417]\n",
            " [0.3613]\n",
            " [0.1079]\n",
            " [0.0349]\n",
            " [0.2011]\n",
            " [0.4244]\n",
            " [0.5442]\n",
            " [0.7288]\n",
            " [0.0026]\n",
            " [0.034 ]\n",
            " [0.3493]\n",
            " [0.1333]\n",
            " [0.2505]\n",
            " [0.4209]\n",
            " [0.0911]\n",
            " [0.2334]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "r2JRWvioJqut",
        "outputId": "482db004-7b80-44dd-d9ff-149ecda90c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(pred==y_test)/len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCbpdTuRu_GH",
        "outputId": "4563332e-8c4e-4103-a77f-19e78da62a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7857142857142857"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment\n",
        "\n",
        "Just follow the class logistic_regression, try to implement Logistic regression with l1, l2 and l1-l2. That we call respectively `Lasso (least absolute shrinkage and selection operator)`, 'Ridge' and 'ElasticNet'.\n",
        "\n",
        "1. l1-regularization (LASSO):\n",
        "* Objective function $l(\\theta)$: \n",
        "\\begin{equation}\n",
        "  -\\sum_{i= 1}^{N} \\left(y_{true} \\times \\log y_{pred} + (1-y_{true}) \\times \\log (1-y_{pred}) \\right)\n",
        "\\end{equation}\n",
        "\n",
        "* \n",
        "\n",
        "2. l2-regularization:\n",
        "\\begin{equation}\n",
        "  -\\sum_{i= 1}^{N} \\left(y_{true} \\times \\log y_{pred} + (1-y_{true}) \\times \\log (1-y_{pred}) \\right)\n",
        "\\end{equation}\n",
        "\n",
        "3. l1-l2-regularization:\n",
        "\\begin{equation}\n",
        "  -\\sum_{i= 1}^{N} \\left(y_{true} \\times \\log y_{pred} + (1-y_{true}) \\times \\log (1-y_{pred}) \\right)\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "9WIvYaFRTEOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class logistic_regression_Regularized_l1:\n",
        "  def __init__(self, num_iters= 100, threshold= 0.5, tolerance= 1e-10, lr= 0.000001, lambd= 10):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    self.num_iters= num_iters\n",
        "    self.threshold= threshold\n",
        "    self.tolerance= tolerance\n",
        "    self.lambd= lambd \n",
        "    self.lr= lr\n",
        "    self.theta= None\n",
        "    self.cost_history= []\n",
        "    #### END CODE ####\n",
        "\n",
        "  def add_ones(self, x):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    x_new= np.concatenate((np.ones((len(x),1)), x), axis = 1)\n",
        "    return x_new\n",
        "    #### END CODE ####\n",
        "\n",
        "  def sigmoid(self, x, theta):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    z= x@theta\n",
        "    return 1/(1 + np.exp(z))\n",
        "    #### END CODE ####\n",
        "\n",
        "  def cross_entropy(self, x, y_true):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    n = x.shape[0]\n",
        "    y_hat = self.sigmoid(x, self.theta)\n",
        "    temp_theta = self.theta[1:].copy()\n",
        "\n",
        "    Cost = -np.sum(y_true*np.log(y_hat)+(1-y_true)*np.log(1-y_hat)) + self.lambd*np.sum(np.abs(temp_theta))\n",
        "        \n",
        "    return Cost/n\n",
        "    #### END CODE ####\n",
        "\n",
        "  def fit(self, x,y):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    x= self.add_ones(x) # Add ones to x\n",
        "    y= y.reshape(-1, 1) # reshape y. This is optional, do it if needed\n",
        "    self.theta= np.zeros((x.shape[1], 1))# Initialize theta to zeros vector >>> (x.shape[1])\n",
        "    current_iter= 1\n",
        "    norm= 1\n",
        "\n",
        "    while (norm >= self.tolerance and current_iter < self.num_iters):\n",
        "      theta_old = self.theta.copy() # Get old theta\n",
        "\n",
        "      # make predictions\n",
        "      y_pred= self.sigmoid(x, self.theta) # using sigmoid function \n",
        "\n",
        "      # Gradient of cross-entropy\n",
        "      grad= x.T@(y - y_pred)+self.lambd*np.sum(np.sign(theta_old))\n",
        "      grad= grad.reshape(-1, 1) # Reshape, if it is needed\n",
        "\n",
        "      # update rules\n",
        "      self.theta= self.theta - self.lr*grad\n",
        "      # Compute the training loss\n",
        "      self.cost_history.append(self.cross_entropy(x, y))\n",
        "\n",
        "      # Convergence criteria:\n",
        "      if current_iter%100 == 0:\n",
        "        print(f'cost for {current_iter} iteration : {self.cross_entropy(x, y)}')\n",
        "      norm = np.linalg.norm(theta_old - self.theta)\n",
        "      current_iter += 1\n",
        "    #### END CODE ####\n",
        "  \n",
        "  def predict(self, x):\n",
        "    proba= self.predict_proba(x) # Get probability of x\n",
        "    result= [1 if i> self.threshold else 0 for i in proba] # Convert proba to 0 or 1. hint: list comprehension\n",
        "    return np.array(result) \n",
        "  \n",
        "    \n",
        "  def predict_proba(self, x):\n",
        "    x= x= self.add_ones(x) # Apply add ones to x\n",
        "    y_pred_prob= self.sigmoid(x, self.theta) # Predict proba with sigmoid\n",
        "    return y_pred_prob\n",
        "  \n",
        "  def plot(self):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Cost')\n",
        "    plt.plot(np.arange(len(self.cost_history)), self.cost_history, 'r', linewidth = \"2\")\n",
        "    plt.show()\n",
        "    #### END CODE ####"
      ],
      "metadata": {
        "id": "oru7W5P6FNyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model by instanciating the class logistic_regression\n",
        "model = logistic_regression_Regularized_l1(num_iters=10000)"
      ],
      "metadata": {
        "id": "0MUUFwZBt1j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dd6dOcBuPpK",
        "outputId": "8a36a62f-3c03-4ab0-b8e4-4fb04ba0a929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost for 100 iteration : 0.6880870105517688\n",
            "cost for 200 iteration : 0.6831997300164869\n",
            "cost for 300 iteration : 0.6784658268316089\n",
            "cost for 400 iteration : 0.6738889269013767\n",
            "cost for 500 iteration : 0.6694547666886024\n",
            "cost for 600 iteration : 0.6651670882989656\n",
            "cost for 700 iteration : 0.6610119265775679\n",
            "cost for 800 iteration : 0.6569848187735491\n",
            "cost for 900 iteration : 0.6530977295003848\n",
            "cost for 1000 iteration : 0.6493292269843552\n",
            "cost for 1100 iteration : 0.6456746813570255\n",
            "cost for 1200 iteration : 0.642138422119394\n",
            "cost for 1300 iteration : 0.6387159987119843\n",
            "cost for 1400 iteration : 0.6353952902393947\n",
            "cost for 1500 iteration : 0.6321804421940361\n",
            "cost for 1600 iteration : 0.6290674732992347\n",
            "cost for 1700 iteration : 0.6260527593642047\n",
            "cost for 1800 iteration : 0.6231249875477499\n",
            "cost for 1900 iteration : 0.620288633552286\n",
            "cost for 2000 iteration : 0.6175401286004114\n",
            "cost for 2100 iteration : 0.6148762732952512\n",
            "cost for 2200 iteration : 0.6122940990362351\n",
            "cost for 2300 iteration : 0.6097834789777532\n",
            "cost for 2400 iteration : 0.6073555782487092\n",
            "cost for 2500 iteration : 0.6049938756695978\n",
            "cost for 2600 iteration : 0.6027093426486712\n",
            "cost for 2700 iteration : 0.6004858754704218\n",
            "cost for 2800 iteration : 0.5983344921211042\n",
            "cost for 2900 iteration : 0.5962395103716603\n",
            "cost for 3000 iteration : 0.5942054746563208\n",
            "cost for 3100 iteration : 0.5922362480295195\n",
            "cost for 3200 iteration : 0.5903234988222372\n",
            "cost for 3300 iteration : 0.5884590899624677\n",
            "cost for 3400 iteration : 0.5866533521848231\n",
            "cost for 3500 iteration : 0.5848982908996232\n",
            "cost for 3600 iteration : 0.5831979162977533\n",
            "cost for 3700 iteration : 0.5815389043680698\n",
            "cost for 3800 iteration : 0.5799310936148115\n",
            "cost for 3900 iteration : 0.5783617036717719\n",
            "cost for 4000 iteration : 0.5768456770420484\n",
            "cost for 4100 iteration : 0.5753651590385799\n",
            "cost for 4200 iteration : 0.5739345821811442\n",
            "cost for 4300 iteration : 0.5725518438539775\n",
            "cost for 4400 iteration : 0.571214949031282\n",
            "cost for 4500 iteration : 0.5699220039948227\n",
            "cost for 4600 iteration : 0.5686712104429399\n",
            "cost for 4700 iteration : 0.5674608599671745\n",
            "cost for 4800 iteration : 0.5662893288738343\n",
            "cost for 4900 iteration : 0.5651550733289566\n",
            "cost for 5000 iteration : 0.5640566248062857\n",
            "cost for 5100 iteration : 0.5629925858189945\n",
            "cost for 5200 iteration : 0.5619616259169923\n",
            "cost for 5300 iteration : 0.5609624779327322\n",
            "cost for 5400 iteration : 0.5599939344594608\n",
            "cost for 5500 iteration : 0.5590548445468438\n",
            "cost for 5600 iteration : 0.5581441105998501\n",
            "cost for 5700 iteration : 0.5572606854676685\n",
            "cost for 5800 iteration : 0.5564035697102908\n",
            "cost for 5900 iteration : 0.5555718090311927\n",
            "cost for 6000 iteration : 0.5547644918653067\n",
            "cost for 6100 iteration : 0.5539807471121944\n",
            "cost for 6200 iteration : 0.5532197420049937\n",
            "cost for 6300 iteration : 0.5524806801063508\n",
            "cost for 6400 iteration : 0.5517627994231267\n",
            "cost for 6500 iteration : 0.5510653706322274\n",
            "cost for 6600 iteration : 0.5503876954104175\n",
            "cost for 6700 iteration : 0.5497291048614558\n",
            "cost for 6800 iteration : 0.5490889580343448\n",
            "cost for 6900 iteration : 0.5484666405269016\n",
            "cost for 7000 iteration : 0.5478615631692466\n",
            "cost for 7100 iteration : 0.5472731607821687\n",
            "cost for 7200 iteration : 0.5467008910056728\n",
            "cost for 7300 iteration : 0.546144233193316\n",
            "cost for 7400 iteration : 0.5456026873682456\n",
            "cost for 7500 iteration : 0.5450757732371153\n",
            "cost for 7600 iteration : 0.5445630292583183\n",
            "cost for 7700 iteration : 0.5440640117612054\n",
            "cost for 7800 iteration : 0.5435782941131805\n",
            "cost for 7900 iteration : 0.5431054659317693\n",
            "cost for 8000 iteration : 0.5426451323389505\n",
            "cost for 8100 iteration : 0.5421969132552078\n",
            "cost for 8200 iteration : 0.5417604427309413\n",
            "cost for 8300 iteration : 0.5413353683130125\n",
            "cost for 8400 iteration : 0.5409213504443563\n",
            "cost for 8500 iteration : 0.5405180618947176\n",
            "cost for 8600 iteration : 0.5401251872206959\n",
            "cost for 8700 iteration : 0.5397424222533997\n",
            "cost for 8800 iteration : 0.5393694736121201\n",
            "cost for 8900 iteration : 0.5390060582425273\n",
            "cost for 9000 iteration : 0.5386519029779994\n",
            "cost for 9100 iteration : 0.5383067441227669\n",
            "cost for 9200 iteration : 0.5379703270556496\n",
            "cost for 9300 iteration : 0.5376424058532294\n",
            "cost for 9400 iteration : 0.5373227429313807\n",
            "cost for 9500 iteration : 0.5370111087041428\n",
            "cost for 9600 iteration : 0.5367072812589788\n",
            "cost for 9700 iteration : 0.5364110460475303\n",
            "cost for 9800 iteration : 0.5361221955910218\n",
            "cost for 9900 iteration : 0.535840529199528\n",
            "CPU times: user 1.32 s, sys: 15.4 ms, total: 1.33 s\n",
            "Wall time: 1.34 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foz1cgVxuPr_",
        "outputId": "029fedfb-55c6-4de7-8849-3ed3ab28440e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6048],\n",
              "       [-0.1709],\n",
              "       [-0.562 ],\n",
              "       [ 0.1018],\n",
              "       [ 0.0422],\n",
              "       [ 0.0306],\n",
              "       [-0.339 ],\n",
              "       [-0.1309],\n",
              "       [-0.1927]])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class logistic_regression_Regularized_l2:\n",
        "  def __init__(self, num_iters= 100, threshold= 0.5, tolerance= 1e-10, lr= 0.00001, lambd= 10):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    self.num_iters= num_iters\n",
        "    self.threshold= threshold\n",
        "    self.tolerance= tolerance\n",
        "    self.lambd= lambd \n",
        "    self.lr= lr\n",
        "    self.theta= None\n",
        "    self.cost_history= []\n",
        "    #### END CODE ####\n",
        "\n",
        "  def add_ones(self, x):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    x_new= np.concatenate((np.ones((len(x),1)), x), axis = 1)\n",
        "    return x_new\n",
        "    #### END CODE ####\n",
        "\n",
        "  def sigmoid(self, x, theta):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    z= x@theta\n",
        "    return 1/(1 + np.exp(z))\n",
        "    #### END CODE ####\n",
        "\n",
        "  def cross_entropy(self, x, y_true):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    n = x.shape[0]\n",
        "    y_hat = self.sigmoid(x, self.theta)\n",
        "    temp_theta = self.theta[1:].copy()\n",
        "\n",
        "    Cost = -np.sum(y_true*np.log(y_hat)+(1-y_true)*np.log(1-y_hat)) + self.lambd*np.sum(temp_theta**2)\n",
        "        \n",
        "    return Cost/n\n",
        "    #### END CODE ####\n",
        "\n",
        "  def fit(self, x,y):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    x= self.add_ones(x) # Add ones to x\n",
        "    y= y.reshape(-1, 1) # reshape y. This is optional, do it if needed\n",
        "    self.theta= np.zeros((x.shape[1], 1))# Initialize theta to zeros vector >>> (x.shape[1])\n",
        "    current_iter= 1\n",
        "    norm= 1\n",
        "\n",
        "    while (norm >= self.tolerance and current_iter < self.num_iters):\n",
        "      theta_old = self.theta.copy() # Get old theta\n",
        "\n",
        "      # make predictions\n",
        "      y_pred= self.sigmoid(x, self.theta) # using sigmoid function \n",
        "\n",
        "      # Gradient of cross-entropy\n",
        "      grad= x.T@(y - y_pred)+self.lambd*np.sum(theta_old)\n",
        "      grad= grad.reshape(-1, 1) # Reshape, if it is needed\n",
        "\n",
        "      # update rules\n",
        "      self.theta= self.theta - self.lr*grad\n",
        "      # Compute the training loss\n",
        "      self.cost_history.append(self.cross_entropy(x, y))\n",
        "\n",
        "      # Convergence criteria:\n",
        "      if current_iter%100 == 0:\n",
        "        print(f'cost for {current_iter} iteration : {self.cross_entropy(x, y)}')\n",
        "      norm = np.linalg.norm(theta_old - self.theta)\n",
        "      current_iter += 1\n",
        "    #### END CODE ####\n",
        "  \n",
        "  def predict(self, x):\n",
        "    proba= self.predict_proba(x) # Get probability of x\n",
        "    result= [1 if i> self.threshold else 0 for i in proba] # Convert proba to 0 or 1. hint: list comprehension\n",
        "    return np.array(result) \n",
        "  \n",
        "    \n",
        "  def predict_proba(self, x):\n",
        "    x= x= self.add_ones(x) # Apply add ones to x\n",
        "    y_pred_prob= self.sigmoid(x, self.theta) # Predict proba with sigmoid\n",
        "    return y_pred_prob\n",
        "  \n",
        "  def plot(self):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Cost')\n",
        "    plt.plot(np.arange(len(self.cost_history)), self.cost_history, 'r', linewidth = \"2\")\n",
        "    plt.show()\n",
        "    #### END CODE ####"
      ],
      "metadata": {
        "id": "Q4MuLTNNT5qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model by instanciating the class logistic_regression\n",
        "model = logistic_regression_Regularized_l2(num_iters=10000)"
      ],
      "metadata": {
        "id": "XAGOhG2evyol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy4AaBg8v__u",
        "outputId": "e8b54c41-9391-4645-90c9-018156c208e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost for 100 iteration : 0.6371359384406019\n",
            "cost for 200 iteration : 0.6012618043757195\n",
            "cost for 300 iteration : 0.5769977261436593\n",
            "cost for 400 iteration : 0.5598307653023828\n",
            "cost for 500 iteration : 0.5472632890368664\n",
            "cost for 600 iteration : 0.5378275568995721\n",
            "cost for 700 iteration : 0.5306097956939508\n",
            "cost for 800 iteration : 0.5250119227208108\n",
            "cost for 900 iteration : 0.5206259084869931\n",
            "cost for 1000 iteration : 0.5171638526333432\n",
            "cost for 1100 iteration : 0.5144170186286707\n",
            "cost for 1200 iteration : 0.5122306917128424\n",
            "cost for 1300 iteration : 0.5104881043397038\n",
            "cost for 1400 iteration : 0.5090997911229356\n",
            "cost for 1500 iteration : 0.5079963259604957\n",
            "cost for 1600 iteration : 0.5071232406134261\n",
            "cost for 1700 iteration : 0.5064373933463008\n",
            "cost for 1800 iteration : 0.5059043266876367\n",
            "cost for 1900 iteration : 0.5054963149445244\n",
            "cost for 2000 iteration : 0.5051909018799577\n",
            "cost for 2100 iteration : 0.5049697924309885\n",
            "cost for 2200 iteration : 0.5048180037978084\n",
            "cost for 2300 iteration : 0.5047232089378421\n",
            "cost for 2400 iteration : 0.5046752243905867\n",
            "cost for 2500 iteration : 0.5046656074689284\n",
            "cost for 2600 iteration : 0.5046873370908336\n",
            "cost for 2700 iteration : 0.5047345591235282\n",
            "cost for 2800 iteration : 0.5048023818818544\n",
            "cost for 2900 iteration : 0.5048867109075919\n",
            "cost for 3000 iteration : 0.5049841147281791\n",
            "cost for 3100 iteration : 0.5050917152080412\n",
            "cost for 3200 iteration : 0.5052070975433676\n",
            "cost for 3300 iteration : 0.5053282360390299\n",
            "cost for 3400 iteration : 0.505453432635567\n",
            "cost for 3500 iteration : 0.5055812657906628\n",
            "cost for 3600 iteration : 0.5057105478113437\n",
            "cost for 3700 iteration : 0.5058402891155067\n",
            "cost for 3800 iteration : 0.5059696682004977\n",
            "cost for 3900 iteration : 0.5060980063317735\n",
            "cost for 4000 iteration : 0.5062247461508307\n",
            "cost for 4100 iteration : 0.5063494335496136\n",
            "cost for 4200 iteration : 0.5064717022769427\n",
            "cost for 4300 iteration : 0.5065912608375354\n",
            "cost for 4400 iteration : 0.5067078813208797\n",
            "cost for 4500 iteration : 0.5068213898593869\n",
            "cost for 4600 iteration : 0.5069316584658426\n",
            "cost for 4700 iteration : 0.5070385980415529\n",
            "cost for 4800 iteration : 0.5071421523805156\n",
            "cost for 4900 iteration : 0.507242293022919\n",
            "cost for 5000 iteration : 0.5073390148343909\n",
            "cost for 5100 iteration : 0.5074323322066002\n",
            "cost for 5200 iteration : 0.5075222757907857\n",
            "cost for 5300 iteration : 0.5076088896891212\n",
            "cost for 5400 iteration : 0.5076922290399991\n",
            "cost for 5500 iteration : 0.5077723579426991\n",
            "cost for 5600 iteration : 0.5078493476748176\n",
            "cost for 5700 iteration : 0.5079232751625133\n",
            "cost for 5800 iteration : 0.5079942216692821\n",
            "cost for 5900 iteration : 0.5080622716737802\n",
            "cost for 6000 iteration : 0.5081275119112981\n",
            "cost for 6100 iteration : 0.5081900305569823\n",
            "cost for 6200 iteration : 0.5082499165318725\n",
            "cost for 6300 iteration : 0.5083072589153855\n",
            "cost for 6400 iteration : 0.5083621464500593\n",
            "cost for 6500 iteration : 0.508414667126257\n",
            "cost for 6600 iteration : 0.508464907836156\n",
            "cost for 6700 iteration : 0.5085129540877403\n",
            "cost for 6800 iteration : 0.5085588897707298\n",
            "cost for 6900 iteration : 0.5086027969674227\n",
            "cost for 7000 iteration : 0.5086447558023333\n",
            "cost for 7100 iteration : 0.5086848443252987\n",
            "cost for 7200 iteration : 0.5087231384234079\n",
            "cost for 7300 iteration : 0.5087597117576992\n",
            "cost for 7400 iteration : 0.5087946357210971\n",
            "cost for 7500 iteration : 0.5088279794145028\n",
            "cost for 7600 iteration : 0.5088598096383514\n",
            "cost for 7700 iteration : 0.5088901908972913\n",
            "cost for 7800 iteration : 0.5089191854159396\n",
            "cost for 7900 iteration : 0.5089468531639363\n",
            "cost for 8000 iteration : 0.5089732518887388\n",
            "cost for 8100 iteration : 0.5089984371548141\n",
            "cost for 8200 iteration : 0.5090224623880484\n",
            "cost for 8300 iteration : 0.5090453789243583\n",
            "cost for 8400 iteration : 0.5090672360616179\n",
            "cost for 8500 iteration : 0.5090880811141365\n",
            "cost for 8600 iteration : 0.5091079594690265\n",
            "cost for 8700 iteration : 0.5091269146438906\n",
            "cost for 8800 iteration : 0.5091449883453377\n",
            "cost for 8900 iteration : 0.5091622205279104\n",
            "cost for 9000 iteration : 0.5091786494530623\n",
            "cost for 9100 iteration : 0.5091943117478824\n",
            "cost for 9200 iteration : 0.5092092424633103\n",
            "cost for 9300 iteration : 0.5092234751316229\n",
            "cost for 9400 iteration : 0.5092370418230169\n",
            "cost for 9500 iteration : 0.5092499732011335\n",
            "cost for 9600 iteration : 0.5092622985774097\n",
            "cost for 9700 iteration : 0.5092740459641536\n",
            "cost for 9800 iteration : 0.5092852421262732\n",
            "cost for 9900 iteration : 0.5092959126315946\n",
            "CPU times: user 1.36 s, sys: 15.1 ms, total: 1.37 s\n",
            "Wall time: 1.37 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM_jTjvlwACx",
        "outputId": "a1d4e072-9eca-43de-9091-ce91d9f8af8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.9575],\n",
              "       [-0.2597],\n",
              "       [-0.9761],\n",
              "       [ 0.2737],\n",
              "       [ 0.0439],\n",
              "       [ 0.2127],\n",
              "       [-0.6655],\n",
              "       [-0.1984],\n",
              "       [-0.2284]])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class logistic_regression_Regularized:\n",
        "  pass"
      ],
      "metadata": {
        "id": "vnHpkvRIT71Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concepts:\n",
        "1. Why there is no close form for cross-entropy loss?\n",
        "2. Why we need cross-entropy loss instead of mse?\n",
        "3. Why is logistic regression a type of classification technique and not a regression?\n",
        "4. Why LASSO perform features selection? "
      ],
      "metadata": {
        "id": "CNLDi_m9qPDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iRpH1NEfzJl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Push your works to Githup Repo\n",
        "\n",
        "Setps:\n",
        "1. Fork the repo;\n",
        "2. Clone in your colab;\n",
        "3. Push\n",
        "4. Make a pull request"
      ],
      "metadata": {
        "id": "ObjYAdUf7S0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "your_token = \"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\"\n",
        "your_repository = \"benjaminbenteke/Logistic_regression\""
      ],
      "metadata": {
        "id": "6UyR30_d0pQP"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://benjaminbenteke:\"$your_token\"@github.com/\"$your_repository\".git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ4aSIowznb8",
        "outputId": "f9ebf5da-7a7d-47e1-d29a-8821346bda27"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Logistic_regression'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp diabetes.csv Logistic_regression/"
      ],
      "metadata": {
        "id": "vt8snlAD132u"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Logistic_regression"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W_1QbRx1mze",
        "outputId": "3e85f717-6f82-45e0-e251-97d42693c5c2"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Logistic_regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YTt-PiU12C3",
        "outputId": "25e26124-b84c-4d00-8534-f120fcf41fd9"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Logistic_regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrnDT3KD5CZR",
        "outputId": "d7969666-a2b4-4f8f-f042-9dae5c8676d5"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31mdiabetes.csv\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYDKd9_K5IDH",
        "outputId": "45b899fd-2cf1-4056-dbc7-b087a9786443"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "origin\thttps://benjaminbenteke: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@github.com/benjaminbenteke/Logistic_regression.git (fetch)\n",
            "origin\thttps://benjaminbenteke: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@github.com/benjaminbenteke/Logistic_regression.git (push)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4bi1s1q5E1s",
        "outputId": "71586a06-db7f-4e7d-e89f-dae6418647dd"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mmain\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"Add my files\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh-ysWgo1it7",
        "outputId": "b99d30b5-c444-47f7-b3f9-8085679d38e7"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@d18c37929172.(none)')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config user.email \"bbenteke@aimsammi.org\"\n",
        "!git config user.name \"benjaminbenteke\""
      ],
      "metadata": {
        "id": "h3ZkL9v75QA5"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsM71z3i2fan",
        "outputId": "f59123de-b9a6-464c-cf05-c9a1548ffa18"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git reset HEAD <file>...\" to unstage)\n",
            "\n",
            "\t\u001b[32mnew file:   diabetes.csv\u001b[m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git pull"
      ],
      "metadata": {
        "id": "JtUoD9XG5a3x"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoPaeIqY2ips",
        "outputId": "f5d4bfe1-0adf-4f6a-98f7-edbe86076d31"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Invalid username or password.\n",
            "fatal: Authentication failed for 'https://benjaminbenteke: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@github.com/benjaminbenteke/Logistic_regression.git/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote set-url origin git@github.com:benjaminbenteke/Logistic_regression.git"
      ],
      "metadata": {
        "id": "nSlfvF9o9IQV"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ2ofFu3-eBw",
        "outputId": "24a7921d-cf6a-424b-cdea-af3ed9dde22e"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Host key verification failed.\r\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --unset-all credential.helper\n",
        "!git config --global --unset-all credential.helper\n",
        "!git config --system --unset-all credential.helper"
      ],
      "metadata": {
        "id": "9KQJOKEI_adK"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %rm -rf Logistic_regression"
      ],
      "metadata": {
        "id": "Xm0uYFoo8xh_"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "rztu7ujx83Eq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7878cc2f-70ec-46e0-d6ad-cf4175e6b751"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MPOixlp9vMc",
        "outputId": "21c39bcb-d00f-4f4c-e083-07f33e22c51a"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Logistic_regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_ktbNC1__jiH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}